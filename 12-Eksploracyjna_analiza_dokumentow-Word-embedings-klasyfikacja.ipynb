{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9c477e",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/jkanclerz/analiza-tekstu/blob/master/12-Eksploracyjna_analiza_dokumentow-Word-embedings-klasyfikacja.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73964fc2",
   "metadata": {},
   "source": [
    "## Klasyfikacja z wykorzystaniem word embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df7e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (1.21.4)\n",
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in ./.venv/lib/python3.9/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.9/site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./.venv/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./.venv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./.venv/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (58.5.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./.venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./.venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./.venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy tensorflow pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc000a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-04 07:53:16--  http://blog.jkan.pl/polish_sentiment_dataset.csv\n",
      "Resolving blog.jkan.pl (blog.jkan.pl)... 85.128.239.15\n",
      "Connecting to blog.jkan.pl (blog.jkan.pl)|85.128.239.15|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 95240804 (91M) [text/csv]\n",
      "Saving to: ‘var/polish_sentiment.csv’\n",
      "\n",
      "var/polish_sentimen 100%[===================>]  90,83M  16,4MB/s    in 5,6s    \n",
      "\n",
      "2021-12-04 07:53:22 (16,3 MB/s) - ‘var/polish_sentiment.csv’ saved [95240804/95240804]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p var\n",
    "!wget http://blog.jkan.pl/polish_sentiment_dataset.csv -O var/polish_sentiment.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e15e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b786b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'var/polish_sentiment.csv'\n",
    "\n",
    "dataset = pd.read_csv(filename, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164a8114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>762836.000000</td>\n",
       "      <td>936817.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>88.486888</td>\n",
       "      <td>0.587340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>97.483536</td>\n",
       "      <td>0.797016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7970.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              length           rate\n",
       "count  762836.000000  936817.000000\n",
       "mean       88.486888       0.587340\n",
       "std        97.483536       0.797016\n",
       "min         0.000000      -1.000000\n",
       "25%        44.000000       1.000000\n",
       "50%        63.000000       1.000000\n",
       "75%       101.000000       1.000000\n",
       "max      7970.000000       1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "879e6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "311948e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['description'].notnull() & dataset['rate'].notnull() & dataset['rate'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eabc6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['description'] = dataset['description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8cef1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    734250\n",
       "-1.0    183391\n",
       "Name: rate, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.rate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dd163c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[dataset['rate'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f961355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56a1b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "280f6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.map(lambda x: x if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8a7c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc727a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 07:54:55.517715: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_train).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f993246e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'i', 'w', 'polecam', 'bardzo', 'z', 'szybka', 'na', 'nie']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04ca70b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (587289,)\n",
      "X_test shape: (183529,)\n",
      "X_val shape: (146823,)\n",
      "y_train shape: (587289,)\n",
      "y_test shape: (183529,)\n",
      "y_val shape: (146823,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"X_val shape: \" + str(X_val.shape))\n",
    "print(\"y_train shape: \" + str(y_train.shape))\n",
    "print(\"y_test shape: \" + str(y_test.shape))\n",
    "print(\"y_val shape: \" + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb3e0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89d0562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = vectorizer([[\"lubię dhl bo szybko dostarczają paczki blef xxxxx\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "531b0467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 407, 1793,   79,   11, 5385,  404])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.numpy()[0, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc46bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf var/nkjp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d57afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-04 08:01:17--  http://dsmodels.nlp.ipipan.waw.pl/dsmodels/nkjp+wiki-forms-all-100-skipg-ns.txt.gz\n",
      "Resolving dsmodels.nlp.ipipan.waw.pl (dsmodels.nlp.ipipan.waw.pl)... 213.135.36.94\n",
      "Connecting to dsmodels.nlp.ipipan.waw.pl (dsmodels.nlp.ipipan.waw.pl)|213.135.36.94|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 808466993 (771M) [application/octet-stream]\n",
      "Saving to: ‘var/nkjp+wiki-forms-all-100-skipg-ns.txt.gz’\n",
      "\n",
      "var/nkjp+wiki-forms 100%[===================>] 771,01M  33,5MB/s    in 22s     \n",
      "\n",
      "2021-12-04 08:01:39 (35,3 MB/s) - ‘var/nkjp+wiki-forms-all-100-skipg-ns.txt.gz’ saved [808466993/808466993]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://dsmodels.nlp.ipipan.waw.pl/dsmodels/nkjp+wiki-forms-all-100-skipg-ns.txt.gz -O var/nkjp+wiki-forms-all-100-skipg-ns.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccaa1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d var/nkjp+wiki-forms-all-100-skipg-ns.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ef7ec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2123132 100\r\n",
      "w 0.466284 -0.360719 0.626233 0.074990 0.511295 -0.050783 -0.284817 -0.560439 0.084301 -0.017775 -0.283048 -0.032232 0.023057 0.111658 0.115480 -0.008415 0.133235 0.205307 0.340641 -0.131821 0.384864 0.038841 0.033434 -0.563962 -0.382250 -0.008713 0.020756 -0.612251 0.236674 -0.552045 -0.433139 0.463721 0.363138 -0.150043 -0.103797 -0.088920 -0.310293 0.190513 -0.074629 0.205998 -0.116720 -0.106180 -0.029671 -0.425457 0.644615 0.224739 -0.401282 0.691186 0.280313 0.040966 -0.086397 0.116823 0.452302 0.159339 -0.065328 0.098123 -0.418321 0.436972 -0.518450 0.030116 0.170335 -0.397297 -0.113067 0.115685 -0.172756 0.137272 0.387522 -0.132569 0.668747 -0.054743 -0.306965 0.215071 0.209518 0.249928 -0.415931 0.214751 0.484958 -0.095062 0.642413 -0.470559 -0.217651 0.322925 -0.473760 -0.445890 -0.423398 0.108468 -0.381243 -0.031808 -0.354203 0.109992 0.242362 0.181020 -0.283963 -0.020929 -0.247558 0.142271 -0.090935 -0.000551 -0.695751 -0.001272\r\n",
      "i 0.190866 -0.259831 0.293700 -0.245805 -0.017243 0.080215 -0.614579 -0.310302 0.090947 0.107019 0.163732 0.292979 0.003118 -0.191063 -0.124168 -0.259983 0.168684 0.417561 0.473223 0.035281 0.430518 0.090735 0.029274 -0.219505 -0.209271 0.256972 -0.124877 -0.434130 0.246963 -0.403094 -0.437341 0.373227 0.458149 -0.170219 -0.378356 0.076715 -0.079570 0.041193 0.027010 0.169801 -0.168683 0.140605 -0.020534 -0.159943 0.172323 -0.366384 -0.251524 0.511818 0.172124 0.188775 -0.221511 0.009423 0.235673 0.243075 -0.031265 0.118065 -0.318417 0.272385 -0.070581 -0.141368 0.194931 -0.474789 0.059489 0.110779 -0.176771 0.194838 -0.063372 -0.182983 0.417916 -0.117317 -0.091880 0.249356 0.109481 -0.034030 -0.160090 0.325958 0.357769 -0.218302 0.480604 -0.137575 -0.318896 0.401190 0.009162 -0.349983 -0.209349 -0.022026 -0.276985 0.261303 -0.129826 -0.038542 0.392828 -0.185234 -0.174392 0.062896 0.038297 0.293325 -0.035992 -0.388956 -0.494285 0.075392\r\n",
      "cat: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "cat var/nkjp+wiki-forms-all-100-skipg-ns.txt | head -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b405242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2123133 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = 'var/nkjp+wiki-forms-all-100-skipg-ns.txt'\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "893bd7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.25185e-01, -2.78460e-02,  4.74960e-02,  2.35574e-01,\n",
       "       -5.23631e-01, -1.79990e-02, -3.86200e-02, -1.08883e-01,\n",
       "       -3.08771e-01, -2.38550e-02,  9.63445e-01, -3.02333e-01,\n",
       "        2.04415e-01, -1.75154e-01, -3.63909e-01,  1.40352e-01,\n",
       "       -2.23939e-01,  4.24170e-01,  4.84920e-02, -3.24568e-01,\n",
       "       -2.28869e-01, -3.01482e-01,  1.52183e-01, -1.79558e-01,\n",
       "        2.15400e-03,  1.88992e-01, -2.66566e-01, -8.45700e-02,\n",
       "        2.72910e-01, -3.14724e-01,  5.63602e-01, -2.10065e-01,\n",
       "        5.31396e-01,  4.52114e-01, -7.42492e-01,  4.49459e-01,\n",
       "       -1.35454e-01,  7.83104e-01,  1.96206e-01,  2.27563e-01,\n",
       "        6.28637e-01, -3.90218e-01, -4.10153e-01,  1.44018e-01,\n",
       "        4.73120e-02,  6.96420e-02,  7.58690e-02, -1.02447e-01,\n",
       "        6.55840e-02,  1.87230e-02,  5.85000e-04, -2.03890e-02,\n",
       "        1.75582e-01,  7.24677e-01, -3.16065e-01,  2.02726e-01,\n",
       "        6.38310e-02,  5.24538e-01, -1.21259e-01, -1.80347e-01,\n",
       "       -2.01140e-02,  1.51751e-01, -3.22533e-01,  1.71430e-01,\n",
       "       -2.49494e-01, -1.53714e-01,  1.63846e-01,  3.76319e-01,\n",
       "        4.05433e-01, -9.34000e-03,  7.34600e-03, -6.96630e-02,\n",
       "       -1.59555e-01, -8.19512e-01, -9.08330e-02, -2.17935e-01,\n",
       "        4.22214e-01, -2.17041e-01, -1.77187e-01, -5.44298e-01,\n",
       "       -7.29170e-01, -4.40341e-01,  1.63498e-01, -4.28629e-01,\n",
       "       -5.93697e-01,  8.09890e-02, -4.24431e-01,  1.88929e-01,\n",
       "        5.70325e-01, -3.58476e-01, -1.86720e-01, -4.74920e-02,\n",
       "       -6.60150e-02, -4.51890e-02, -4.54621e-01,  6.29000e-01,\n",
       "        6.32587e-01, -3.00932e-01, -7.60830e-02,  1.63018e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['lubię']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1c242f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29fedfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20002, 100)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8982aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 18290 words (1710 misses)\n"
     ]
    }
   ],
   "source": [
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d950b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec8b2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_count = len(list(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd0b2ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b536a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         2000200   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 128)         64128     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, None, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 128)         82048     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, None, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, None, 128)         82048     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,245,194\n",
      "Trainable params: 244,994\n",
      "Non-trainable params: 2,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(classes_count, activation=\"softmax\")(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c4ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in X_val])).numpy()\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834badc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de55e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=3, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d958ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "\n",
    "preds = model(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "probabilities = end_to_end_model.predict(\n",
    "    [\n",
    "        [X[0]],\n",
    "        [X[1]],\n",
    "        ['Nie polecam tego alegrowicza'],\n",
    "        ['Beznadziejny sklep. Przesłali skisłą paletkę do makijażu, bardzo kłopotliwa reklamacja: stos formularzy do wypełnienia i potem jeszcze maile z pytaniami o nr konta do zwrotu. Zrobili zwrot zamiast reklamacji, zero rekompensaty za mój stracony czas i nerwy; ich obsługa klienta to żart.'],\n",
    "        ['Od miesiąca jestem systematycznie spamowany prośbami o opinię.'],\n",
    "        ['Pomysł na to, żeby wysyłać jedno zamówienie na 4 produkty w dwóch osobnych paczkach, które w dodatku przychodzą w różnym czasie jest bez sensu. Szczególnie w czasach, kiedy dba się o ekologię.'],\n",
    "        ['Proszę nie wysyłać mi więcej wiadomości od tej firmy Nie chce dostawać żadnych więcej meilow Zgłaszam to już wcześniej ale jak widać nikt tym się nie zajął... Porażka'],\n",
    "        ['Dostawa dramat prawie tydzień oczekiwania na przesyłkę']\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c731b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[class_names[np.argmax(x)] for x in probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8fe7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
